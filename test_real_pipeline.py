#!/usr/bin/env python3
"""
ì‹¤ì œ Reddit ë°ì´í„°ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
ë¡œì»¬ì—ì„œ Reddit ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  Vercel APIë¡œ ì²˜ë¦¬
"""

import requests
import json
import time
from typing import Dict, Any, List

# API ì„¤ì •
API_BASE_URL = "https://reddit-crawl-mvp.vercel.app"
HEADERS = {
    "Content-Type": "application/json",
    "User-Agent": "Reddit-Ghost-Publisher-Test/1.0"
}

def get_real_reddit_data(subreddit: str = "programming", limit: int = 3) -> List[Dict[str, Any]]:
    """ì‹¤ì œ Reddit ë°ì´í„° ìˆ˜ì§‘ (ë¡œì»¬ì—ì„œ)"""
    print(f"ğŸ” Fetching real Reddit data from r/{subreddit}...")
    
    try:
        reddit_url = f"https://www.reddit.com/r/{subreddit}/hot.json?limit={limit}"
        response = requests.get(reddit_url, headers={
            "User-Agent": "reddit-ghost-publisher/1.0.0 (by /u/reddit-publisher)"
        }, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            posts = []
            
            if data.get('data') and data['data'].get('children'):
                for child in data['data']['children']:
                    post = child['data']
                    
                    # í•„í„°ë§: NSFW, ìŠ¤í‹°í‚¤, ì‚­ì œëœ ê²Œì‹œê¸€ ì œì™¸
                    if post.get('over_18') or post.get('stickied') or not post.get('title'):
                        continue
                    
                    post_data = {
                        'reddit_post_id': post.get('id'),
                        'title': post.get('title'),
                        'subreddit': post.get('subreddit'),
                        'author': post.get('author'),
                        'score': post.get('score', 0),
                        'num_comments': post.get('num_comments', 0),
                        'created_utc': post.get('created_utc'),
                        'url': post.get('url'),
                        'selftext': post.get('selftext', ''),
                        'permalink': f"https://reddit.com{post.get('permalink', '')}",
                        'over_18': post.get('over_18', False),
                        'thumbnail': post.get('thumbnail') if post.get('thumbnail') not in ['self', 'default'] else None,
                        'domain': post.get('domain'),
                        'is_video': post.get('is_video', False)
                    }
                    posts.append(post_data)
                    
                    if len(posts) >= limit:
                        break
            
            print(f"âœ… Successfully fetched {len(posts)} real Reddit posts")
            for i, post in enumerate(posts[:3]):
                print(f"   {i+1}. {post['title'][:60]}... (Score: {post['score']})")
            
            return posts
        else:
            print(f"âŒ Failed to fetch Reddit data: HTTP {response.status_code}")
            return []
            
    except Exception as e:
        print(f"âŒ Error fetching Reddit data: {str(e)}")
        return []

def test_ai_with_real_data(post: Dict[str, Any]) -> Dict[str, Any]:
    """ì‹¤ì œ Reddit ë°ì´í„°ë¡œ AI ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ¤– Testing AI processing with real Reddit post...")
    print(f"   ğŸ“ Title: {post['title'][:60]}...")
    
    payload = {
        "title": post['title'],
        "content": post['selftext'] if post['selftext'] else post['url'],
        "subreddit": post['subreddit']
    }
    
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/ai-process", 
            headers=HEADERS, 
            json=payload,
            timeout=60
        )
        data = response.json()
        
        if response.status_code == 200 and data.get('success'):
            processed_data = data.get('data', {})
            
            print("âœ… AI Processing: SUCCESS")
            
            # ì‹¤ì œ AI ì²˜ë¦¬ ê²°ê³¼ í™•ì¸
            if 'korean_summary' in processed_data:
                print("   ğŸ‰ Real AI processing detected!")
                print(f"   ğŸ“ Korean Summary: {processed_data['korean_summary'][:100]}...")
                print(f"   ğŸ·ï¸ Tags: {processed_data.get('tags', [])}")
                print(f"   ğŸ’° Cost: ${processed_data.get('token_usage', {}).get('estimated_cost_usd', 0):.6f}")
                return {"success": True, "real_ai": True, "data": processed_data}
            else:
                print("   âš ï¸ Mock AI processing (API key not configured)")
                print(f"   ğŸ“ Enhanced Title: {processed_data.get('enhanced_title', 'N/A')}")
                return {"success": True, "real_ai": False, "data": processed_data}
        else:
            print(f"âŒ AI Processing failed: {data.get('error', 'Unknown error')}")
            return {"success": False, "error": data.get('error')}
            
    except Exception as e:
        print(f"âŒ AI Processing error: {str(e)}")
        return {"success": False, "error": str(e)}

def test_ghost_with_processed_data(title: str, content: str, tags: List[str]) -> Dict[str, Any]:
    """ì²˜ë¦¬ëœ ë°ì´í„°ë¡œ Ghost ë°œí–‰ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ‘» Testing Ghost publishing...")
    print(f"   ğŸ“ Title: {title[:60]}...")
    
    payload = {
        "title": title,
        "content": content,
        "tags": tags
    }
    
    try:
        response = requests.post(
            f"{API_BASE_URL}/api/ghost-publish", 
            headers=HEADERS, 
            json=payload,
            timeout=30
        )
        data = response.json()
        
        if response.status_code == 200 and data.get('success'):
            published_data = data.get('data', {})
            
            if published_data.get('published'):
                print("âœ… Ghost Publishing: REAL PUBLISH SUCCESS!")
                print(f"   ğŸ”— Published URL: {published_data.get('ghost_url')}")
                print(f"   ğŸ†” Ghost Post ID: {published_data.get('ghost_post_id')}")
                return {"success": True, "real_publish": True, "data": published_data}
            else:
                print("âœ… Ghost Publishing: Mock mode (API key not configured)")
                print(f"   ğŸ“ Mock URL: {published_data.get('mock_data', {}).get('ghost_url', 'N/A')}")
                return {"success": True, "real_publish": False, "data": published_data}
        else:
            print(f"âŒ Ghost Publishing failed: {data.get('error', 'Unknown error')}")
            return {"success": False, "error": data.get('error')}
            
    except Exception as e:
        print(f"âŒ Ghost Publishing error: {str(e)}")
        return {"success": False, "error": str(e)}

def run_real_pipeline_test():
    """ì‹¤ì œ ë°ì´í„°ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ Real Data Pipeline Test")
    print("=" * 60)
    
    # 1. ì‹¤ì œ Reddit ë°ì´í„° ìˆ˜ì§‘
    reddit_posts = get_real_reddit_data("programming", 3)
    
    if not reddit_posts:
        print("âŒ No Reddit posts fetched. Cannot continue test.")
        return
    
    # 2. ì²« ë²ˆì§¸ í¬ìŠ¤íŠ¸ë¡œ AI ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    test_post = reddit_posts[0]
    ai_result = test_ai_with_real_data(test_post)
    
    if not ai_result["success"]:
        print("âŒ AI processing failed. Using original post for Ghost test.")
        title = test_post["title"]
        content = test_post["selftext"] if test_post["selftext"] else f"Original post: {test_post['url']}"
        tags = ["reddit", test_post["subreddit"], "test"]
    else:
        processed = ai_result["data"]
        if ai_result.get("real_ai"):
            title = test_post["title"]  # ì›ë³¸ ì œëª© ì‚¬ìš©
            content = processed.get("korean_summary", processed.get("enhanced_content", ""))
            tags = processed.get("tags", ["reddit", test_post["subreddit"]])
        else:
            title = processed.get("enhanced_title", test_post["title"])
            content = processed.get("enhanced_content", test_post["selftext"] or test_post["url"])
            tags = processed.get("tags", ["reddit", test_post["subreddit"]])
    
    # 3. Ghost ë°œí–‰ í…ŒìŠ¤íŠ¸
    ghost_result = test_ghost_with_processed_data(title, content, tags)
    
    # 4. ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“‹ REAL PIPELINE TEST SUMMARY")
    print("=" * 60)
    
    print(f"Reddit Data Collection: âœ… SUCCESS ({len(reddit_posts)} posts)")
    print(f"AI Processing: {'âœ… REAL AI' if ai_result.get('success') and ai_result.get('real_ai') else 'âš ï¸ MOCK MODE'}")
    print(f"Ghost Publishing: {'âœ… REAL PUBLISH' if ghost_result.get('success') and ghost_result.get('real_publish') else 'âš ï¸ MOCK MODE'}")
    
    if ai_result.get("real_ai") and ghost_result.get("real_publish"):
        print("\nğŸ‰ FULL REAL PIPELINE SUCCESS!")
        print("   All APIs are working with real data and credentials!")
    elif ai_result.get("success") and ghost_result.get("success"):
        print("\nâš ï¸ PIPELINE WORKING IN MOCK MODE")
        print("   APIs are functional but need environment variables configured.")
        print("   Required: OPENAI_API_KEY, GHOST_ADMIN_KEY")
    else:
        print("\nâŒ PIPELINE HAS ISSUES")
        print("   Some APIs are not responding correctly.")
    
    return {
        "reddit_posts": len(reddit_posts),
        "ai_success": ai_result.get("success", False),
        "ai_real": ai_result.get("real_ai", False),
        "ghost_success": ghost_result.get("success", False),
        "ghost_real": ghost_result.get("real_publish", False)
    }

if __name__ == "__main__":
    results = run_real_pipeline_test()